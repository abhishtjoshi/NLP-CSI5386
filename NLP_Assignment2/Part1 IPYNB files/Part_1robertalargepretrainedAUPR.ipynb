{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-01T00:06:36.559990Z",
     "iopub.status.busy": "2022-12-01T00:06:36.559060Z",
     "iopub.status.idle": "2022-12-01T00:06:39.150933Z",
     "shell.execute_reply": "2022-12-01T00:06:39.149391Z",
     "shell.execute_reply.started": "2022-12-01T00:06:36.559892Z"
    }
   },
   "outputs": [],
   "source": [
    "`!cp -r /kaggle/input/nlp-a2/cuad-main /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T00:07:00.102595Z",
     "iopub.status.busy": "2022-12-01T00:07:00.101646Z",
     "iopub.status.idle": "2022-12-01T00:07:00.699709Z",
     "shell.execute_reply": "2022-12-01T00:07:00.698576Z",
     "shell.execute_reply.started": "2022-12-01T00:07:00.102544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/kaggle/working/cuad-main/data/train_separate_questions.json\") as fp:\n",
    "    data = json.load(fp)\n",
    "cnt = 0\n",
    "t_data = []\n",
    "for x in data[\"data\"]:\n",
    "    con_len = len(x[\"paragraphs\"][0][\"context\"].split()) \n",
    "    if con_len < 512:\n",
    "        cnt += 1\n",
    "        if cnt == 16:\n",
    "            break\n",
    "        t_data.append(x)\n",
    "print(cnt)\n",
    "data[\"data\"] = t_data\n",
    "data = json.dumps(data)\n",
    "with open(\"/kaggle/working/cuad-main/data/train.json\",\"w\") as fp:\n",
    "    fp.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T00:07:06.596579Z",
     "iopub.status.busy": "2022-12-01T00:07:06.596226Z",
     "iopub.status.idle": "2022-12-01T00:07:06.662420Z",
     "shell.execute_reply": "2022-12-01T00:07:06.661434Z",
     "shell.execute_reply.started": "2022-12-01T00:07:06.596546Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/working/cuad-main/data/test.json\") as fp:\n",
    "    data = json.load(fp)\n",
    "cnt = 0\n",
    "t_data = []\n",
    "for x in data[\"data\"]:\n",
    "    con_len = len(x[\"paragraphs\"][0][\"context\"].split())\n",
    "    if  con_len < 512:\n",
    "        cnt+=1\n",
    "        if cnt == 4:\n",
    "            break\n",
    "        t_data.append(x)\n",
    "data[\"data\"] = t_data\n",
    "data = json.dumps(data)\n",
    "with open(\"/kaggle/working/cuad-main/data/test_final.json\",\"w\") as fp:\n",
    "    fp.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T00:07:15.960435Z",
     "iopub.status.busy": "2022-12-01T00:07:15.959686Z",
     "iopub.status.idle": "2022-12-01T00:07:15.964755Z",
     "shell.execute_reply": "2022-12-01T00:07:15.963706Z",
     "shell.execute_reply.started": "2022-12-01T00:07:15.960397Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/working/cuad-main/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T00:12:26.450782Z",
     "iopub.status.busy": "2022-12-01T00:12:26.450372Z",
     "iopub.status.idle": "2022-12-01T00:12:40.016739Z",
     "shell.execute_reply": "2022-12-01T00:12:40.015310Z",
     "shell.execute_reply.started": "2022-12-01T00:12:26.450745Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/roberta-large /kaggle/working/cuad-main/pre_trained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T00:13:43.141627Z",
     "iopub.status.busy": "2022-12-01T00:13:43.141248Z",
     "iopub.status.idle": "2022-12-01T00:13:43.178525Z",
     "shell.execute_reply": "2022-12-01T00:13:43.177487Z",
     "shell.execute_reply.started": "2022-12-01T00:13:43.141593Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "IOU_THRESH = 0.5\n",
    "\n",
    "def get_questions_from_csv():\n",
    "    df = pd.read_csv(\"category_descriptions.csv\")\n",
    "    q_dict = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        category = df.iloc[i, 0].split(\"Category: \")[1]\n",
    "        description = df.iloc[i, 1].split(\"Description: \")[1]\n",
    "        q_dict[category.title()] = description\n",
    "    return q_dict\n",
    "\n",
    "qtype_dict = get_questions_from_csv()\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        dict = json.load(f)\n",
    "    return dict\n",
    "\n",
    "\n",
    "def get_preds(nbest_preds_dict, conf=None):\n",
    "    results = {}\n",
    "    for question_id in nbest_preds_dict:\n",
    "        list_of_pred_dicts = nbest_preds_dict[question_id]\n",
    "        preds = {}\n",
    "        for pred_dict in list_of_pred_dicts:\n",
    "            text = pred_dict[\"text\"]\n",
    "            prob = pred_dict[\"probability\"]\n",
    "            if not text == \"\":  # don't count empty string as a prediction\n",
    "                preds[text] = prob\n",
    "        preds_list = [pred for pred in preds.keys() if preds[pred] > conf]\n",
    "        results[question_id] = preds_list\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_answers(test_json_dict):\n",
    "    results = {}\n",
    "\n",
    "    data = test_json_dict[\"data\"]\n",
    "    for contract in data:\n",
    "        for para in contract[\"paragraphs\"]:\n",
    "            qas = para[\"qas\"]\n",
    "            for qa in qas:\n",
    "                id = qa[\"id\"]\n",
    "                answers = qa[\"answers\"]\n",
    "                answers = [answers[i][\"text\"] for i in range(len(answers))]\n",
    "                results[id] = answers\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_jaccard(gt, pred):\n",
    "    remove_tokens = [\".\", \",\", \";\", \":\"]\n",
    "    for token in remove_tokens:\n",
    "        gt = gt.replace(token, \"\")\n",
    "        pred = pred.replace(token, \"\")\n",
    "    gt = gt.lower()\n",
    "    pred = pred.lower()\n",
    "    gt = gt.replace(\"/\", \" \")\n",
    "    pred = pred.replace(\"/\", \" \")\n",
    "\n",
    "    gt_words = set(gt.split(\" \"))\n",
    "    pred_words = set(pred.split(\" \"))\n",
    "\n",
    "    intersection = gt_words.intersection(pred_words)\n",
    "    union = gt_words.union(pred_words)\n",
    "    jaccard = len(intersection) / len(union)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def compute_precision_recall(gt_dict, preds_dict, category=None):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for key in gt_dict:\n",
    "        if category and category not in key:\n",
    "            continue\n",
    "\n",
    "        substr_ok = \"Parties\" in key\n",
    "\n",
    "        answers = gt_dict[key]\n",
    "        preds = preds_dict[key]\n",
    "\n",
    "        # first check if answers is empty\n",
    "        if len(answers) == 0:\n",
    "            if len(preds) > 0:\n",
    "                fp += len(preds)  # false positive for each one\n",
    "        else:\n",
    "            for ans in answers:\n",
    "                assert len(ans) > 0\n",
    "                # check if there is a match\n",
    "                match_found = False\n",
    "                for pred in preds:\n",
    "                    if substr_ok:\n",
    "                        is_match = get_jaccard(ans, pred) >= IOU_THRESH or ans in pred\n",
    "                    else:\n",
    "                        is_match = get_jaccard(ans, pred) >= IOU_THRESH\n",
    "                    if is_match:\n",
    "                        match_found = True\n",
    "\n",
    "                if match_found:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "\n",
    "            # now also get any fps by looping through preds\n",
    "            for pred in preds:\n",
    "                # Check if there's a match. if so, don't count (don't want to double count based on the above)\n",
    "                # but if there's no match, then this is a false positive.\n",
    "                # (Note: we get the true positives in the above loop instead of this loop so that we don't double count\n",
    "                # multiple predictions that are matched with the same answer.)\n",
    "                match_found = False\n",
    "                for ans in answers:\n",
    "                    assert len(ans) > 0\n",
    "                    if substr_ok:\n",
    "                        is_match = get_jaccard(ans, pred) >= IOU_THRESH or ans in pred\n",
    "                    else:\n",
    "                        is_match = get_jaccard(ans, pred) >= IOU_THRESH\n",
    "                    if is_match:\n",
    "                        match_found = True\n",
    "\n",
    "                if not match_found:\n",
    "                    fp += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else np.nan\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else np.nan\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def process_precisions(precision):\n",
    "    \"\"\"\n",
    "    Processes precisions to ensure that precision and recall don't both get worse\n",
    "    Assumes the list precision is sorted in order of recalls\n",
    "    \"\"\"\n",
    "    precision_best = precision[::-1]\n",
    "    for i in range(1, len(precision_best)):\n",
    "        precision_best[i] = max(precision_best[i-1], precision_best[i])\n",
    "    precision = precision_best[::-1]\n",
    "    return precision\n",
    "\n",
    "\n",
    "def get_prec_at_recall(precisions, recalls, confs, recall_thresh=0.9):\n",
    "    \"\"\"\n",
    "    Assumes recalls are sorted in increasing order\n",
    "    \"\"\"\n",
    "    processed_precisions = process_precisions(precisions)\n",
    "    prec_at_recall = 0\n",
    "    for prec, recall, conf in zip(processed_precisions, recalls, confs):\n",
    "        if recall >= recall_thresh:\n",
    "            prec_at_recall = prec\n",
    "            break\n",
    "    return prec_at_recall, conf\n",
    "\n",
    "\n",
    "def get_precisions_recalls(pred_dict, gt_dict, category=None):\n",
    "    precisions = [1]\n",
    "    recalls = [0]\n",
    "    confs = []\n",
    "    for conf in list(np.arange(0.99, 0, -0.01)) + [0.001, 0]:\n",
    "        conf_thresh_pred_dict = get_preds(pred_dict, conf)\n",
    "        prec, recall = compute_precision_recall(gt_dict, conf_thresh_pred_dict, category=category)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(recall)\n",
    "        confs.append(conf)\n",
    "    return precisions, recalls, confs\n",
    "\n",
    "\n",
    "def get_aupr(precisions, recalls):\n",
    "    processed_precisions = process_precisions(precisions)\n",
    "    aupr = metrics.auc(recalls, processed_precisions)\n",
    "    if np.isnan(aupr):\n",
    "        return 0\n",
    "    return aupr\n",
    "\n",
    "\n",
    "def get_results(model_path, gt_dict, verbose=False):\n",
    "    predictions_path = os.path.join(model_path, \"nbest_predictions_.json\")\n",
    "    name = model_path.split(\"/\")[-1]\n",
    "\n",
    "    pred_dict = load_json(predictions_path)\n",
    "\n",
    "    assert sorted(list(pred_dict.keys())) == sorted(list(gt_dict.keys()))\n",
    "\n",
    "    precisions, recalls, confs = get_precisions_recalls(pred_dict, gt_dict)\n",
    "    prec_at_90_recall, _ = get_prec_at_recall(precisions, recalls, confs, recall_thresh=0.9)\n",
    "    prec_at_80_recall, _ = get_prec_at_recall(precisions, recalls, confs, recall_thresh=0.8)\n",
    "    aupr = get_aupr(precisions, recalls)\n",
    "\n",
    "    print(\"AUPR: {:.3f}, Precision at 80% Recall: {:.3f}, Precision at 90% Recall: {:.3f}\".format(aupr, prec_at_80_recall, prec_at_90_recall))\n",
    "\n",
    "    # now save results as a dataframe and return\n",
    "    results = {\"name\": name, \"aupr\": aupr, \"prec_at_80_recall\": prec_at_80_recall, \"prec_at_90_recall\": prec_at_90_recall}\n",
    "    return results\n",
    "\n",
    "\n",
    "# if _name_ == \"_main_\":\n",
    "#     test_json_path = \"./data/test.json\"\n",
    "#     model_path = \"./trained_models/roberta-base\"\n",
    "#     save_dir = \"./results\"\n",
    "#     if not os.path.exists(save_dir): os.mkdir(save_dir)\n",
    "\n",
    "#     gt_dict = load_json(test_json_path)\n",
    "#     gt_dict = get_answers(gt_dict)\n",
    "\n",
    "#     results = get_results(model_path, gt_dict, verbose=True)\n",
    "\n",
    "#     save_path = os.path.join(save_dir, \"{}.json\".format(model_path.split(\"/\")[-1]))\n",
    "#     with open(save_path, \"w\") as f:\n",
    "#         f.write(\"{}\\n\".format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T00:19:28.585206Z",
     "iopub.status.busy": "2022-12-01T00:19:28.584855Z",
     "iopub.status.idle": "2022-12-01T00:19:45.970010Z",
     "shell.execute_reply": "2022-12-01T00:19:45.968940Z",
     "shell.execute_reply.started": "2022-12-01T00:19:28.585173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPR: 0.482, Precision at 80% Recall: 0.381, Precision at 90% Recall: 0.000\n"
     ]
    }
   ],
   "source": [
    "gt_dict = load_json(\"./data/test.json\")\n",
    "gt_dict = get_answers(gt_dict)\n",
    "len(gt_dict.keys())\n",
    "results = get_results(\"./pre_trained/roberta-large/\", gt_dict, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
